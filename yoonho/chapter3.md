# Chapter3 신경망

퍼셉트론으로 복잡한 처리도 이론상 표현할 수 있지만 가중치를 정하는 등의 작업은 여전히 수동으로 처리   
신경망은 데이터로부터 자동으로 가중치 매개변수를 학습

---
## 3.1 퍼셉트론에서 신경망으로

* 입력층, 은닉층, 출력층
    * 은닉층의 뉴런은 사람 눈에 보이지않음

* 조건 분기의 동작을 활성화 함수 h(x)로 나타냄

## 3.2 활성화 함수

* 시그모이드 함수
    * h(x) = 1/1+exp(-x)
    * 비선형 함수
* 활성화 함수로 선형 함수를 사용하면 층을 아무리 깊게해도 은닉층이 없는 네트워크와 같은 기능을 함
* 층을 쌓는 혜택을 얻고싶다면 활성화 함수는 반드시 비선형 함수를 사용해야 함
* ReLU 함수
    * 입력이 0을 넘으면 그 입력을 그대로 출력하고, 0 이하이먄 0을 출력

## 3.3 다차원 배열의 계산
* 행렬의 곱으로 신경망의 계산을 수행할 수 있음

## 3.4 3층 신경망 구현하기
## 3.5 출력층 설계하기
* 항등 함수
    * 입력을 그대로 출력
* 소프트맥스 함수
    * 지수함수의 범위가 너무 커지기 때문에 지수 함수 계산 시 임의의 정수 빼기(입력 값중 최댓값)
    * 자원 낭비를 줄이고자 추론 단계에선 보통 생략

## 3.6 손글씨 숫자 인식
## 3.7 정리
* 신경망에서는 활성화 함수로 시그모이드 함수와 ReLU 함수 같은 매끄럽게 변화하는 함수를 이용한다.
* 넘파이의 다차원 배열을 잘 사용하면 신경망을 효율적으로 구현할 수 있다.
* 기계학습 문제는 크게 회귀와 분류로 나눌 수 있다.
* 출력층의 활성화 함수로는 회귀에서는 주로 항등 함수를, 분류에서는 주로 소프트맥스 함수를 이용한다.
* 분류시에서는 출력층의 뉴런 수를 분류하려는 클래스 수와 같게 설정한다.
* 입력 데이터를 묶은 것을 배치라 하며, 추론 처리를 이 배치 단위로 진행하면 결과를 훨씬 빠르게 얻을 수 있다.
