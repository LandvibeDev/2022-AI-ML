# 7 합성곱 신경망(CNN)
- 이미지 인식과 음성 인식 등 다양한 곳에서 사용된다
## 7.1 전체 구조
- 합성곱 계층과 풀링 계층 등장

![image](https://user-images.githubusercontent.com/91449518/182574199-67b7c33d-d721-45bc-a8fc-4df7062fa41f.png)

## 7.2 합성곱 계층
### 7.2.1 완전연결 계층의 문제점
- 데이터의 형상이 무시된다
- 합성곱 계층은 형상을 유지한다
- CNN에서는 이미지처럼 형상을 가진 데이터를 제대로 이해할 가능성이 있다
- CNN에서는 합성곱 계층의 입출력 데이터를 특징맵이라고 한다
- 합성곱 계층의 입력 데이터를 입력 특징 맵, 출력 데이터를 출력 특징 맵이라고 한다
### 7.2.2 합성곱 연산
- 합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당한다
- 필터를 커널이라고도 함
- 합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용함
- 단일 곱셈-누산 후 해당 장소에 저장
- CNN에서는 필터의 매개변수가 가중치에 해당
- 편향은 항상 하나(1x1)만 존재

![image](https://user-images.githubusercontent.com/91449518/182591636-0d85e551-210a-4b30-90ca-df2d81a1f1a1.png)

### 7.2.3 패딩
- 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값으로 채우는 것을 패딩이라 한다

![image](https://user-images.githubusercontent.com/91449518/182592342-25adcfcc-cd52-44d1-a92c-a45fa1ae9f3d.png)

### 7.2.4 스트라이드
- 필터를 적용하는 위치의 간겨을 스트라이드라고 한다
- 입력 크기(H,W), 필터 크기(FH,FW), 출력 크기(OH,OW), 패딩(P), 스트라이드(S) 사이의 관계식
- $$OH = \frac{H + 2P - FH}{S} + 1$$
- $$OW = \frac{W + 2P - FW}{S} + 1$$
### 7.2.5 3차원 데이터의 합성곱 연산
- 2차원일 때랑 비교하면 채널 방향으로 특징 맵이 늘어났다
- 입력 데이터의 채널 수와 필터의 채널 수는 같아야 한다
### 7.2.6 블록으로 생각하기
- 3차원의 합성곱 연산은 데이터와 필터를 직육면체 블록이라고 생각하면 쉽다
- 합성곱 연산의 출력을 다수의 채널로 내보내기 위해 필터를 여러개 적용시킨다
- 편향은 채널 한개에 값 하나씩으로 구성된다
### 7.2.7 배치 처리
- 합성곱 또한 효율을 높이기 위해 배치 처리를 한다
- 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장한다
## 7.3 풀링 계층
- 세로 가로 방향의 공간을 줄이는 연산이다
- 최대 풀링은 영역에서 최대값을 구하는 연산이다
### 7.3.1 풀링 계층의 특징
- 학습해야 할 매개변수가 없다
- 채널수가 변하지 않는다
- 입력의 변화에 영향을 적게 받는다(강건하다)
## 7.4 합성곱/풀링 계층 구현하기
- 오차역전파법에서 사용했던 forward와 backward 메서드를 추가해 모율로 이용
### 7.4.1 4차원 배열
- CNN에서 계층 사이를 흐르는 데이터는 4차원이다
### 7.4.2 im2col로 데이터 전개하기
- 합성곱 구현을 위해 im2col(4차원 -> 2차원)을 for문 대신 사용
### 7.4.3 합성곱 계층 구현하기/ 7.4.4 풀링 계층 구현하기
## 7.5 CNN 구현하기
## 7.6 CNN 시각화하기
### 7.6.1 1번째 층의 가중치 시각화하기






