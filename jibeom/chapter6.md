# 6.학습 관련 기술들
## 6.1 매개변수 갱신
- 매개변수의 최적값을 찾는 문제를 최적화라 한다
- 매개변수의 최적의 값을 갱신하며 최적의 값에 다가가는 것이 확률적 경사 하강법(SGD)이다
### 6.1.1 모험가 이야기
- 현위치의 기울기만으로 제일 깊은 곳으로 이동한다
### 6.1.2 확률적 경사 하강법(SGD)
- $$W \leftarrow W - \eta \frac{dL}{dW}$$
### 6.1.3 SGD의 단점
- 비등방성 함수에서는 탐색 경로가 비효율적이다
- 기울어진 방향이 본래의 최솟값과 다른 방향을 가리켜서 문제이다
- 모멘텀, AdaGrad, Adam이 SGD의 단점을 개선해주는 대체 기법이다
### 6.1.4 모멘텀
